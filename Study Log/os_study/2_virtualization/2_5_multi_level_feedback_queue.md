---
title: "2.5 Scheduling: The Multi-Level Feedback Queue"
order: "6"
---
[[Study Log/os_study/0_ostep_index|Return to Index]]

## 2.5 Scheduling: The Multi-Level Feedback Queue

上一节我们提到，其实OS大多数情况都很难知道一个任务的长度。所以如果不知道，我们怎么设计一个调度策略，又能有不错的性能，又能满足公平呢？这就是本节的问题。

### 2.5.1 MLFQ: Basic Rules

**Corbato et al.** 设计了一个策略，叫做**Multi-level Feedback Queue (MLFQ)**，也正是这个东西让他获得了图灵奖。

MLFQ的实现有很多，但是他们都有很多相似的特点。

MLFQ不是一个队列，而是**一堆队列**。每一个队列都有一个**优先级**。运行规则：

- 优先级高的队列中的任务会先运行；
- 同一个队列中内部的任务使用Round Robin运行。

那现在问题就变成了：MLFQ是怎么给队列分配优先级的。答案是：**通过观察任务的表现**。如果一个任务不停地在释放CPU，为了等待用户输入（比如shell就是这样），那么MLFQ就会将它的优先级调高，这样就能快速响应用户的输入；如果一个任务总是大量密集消耗CPU（好像解压软件就是这样），那么MLFQ就会适当调低优先级。因为这些任务虽然很需要CPU，但是并没有响应时间的需求。

> [!question]- 等待用户输入的任务明明没多少指令要执行，那为什么还要提高优先级呢？
> 这个问题我问了GPT：
> > 等待输入的作业通常属于交互式进程，比如用户输入命令、点击按钮等。这些任务优先级高的原因在于，它们需要快速响应用户操作，以提供良好的用户体验。
> >
> > 尽管等待输入的作业在等待期间不会占用CPU资源，但一旦输入到达，它们往往需要立即处理以保持系统的交互性。如果这些任务的优先级较低，系统可能会推迟处理它们，从而导致用户感到延迟或卡顿。因此，多级反馈队列调度算法（MLFQ）将这些任务的优先级设置得较高，以确保它们能够迅速获得CPU资源并及时处理，从而提升系统的响应速度和用户体验。
> >
> > 相比之下，CPU密集型任务虽然需要大量的计算资源，但通常不会直接影响用户的操作体验，因此它们的优先级可以适当降低，以让出资源给那些需要快速响应的交互式任务。

另外，MLFQ还会进行自我学习。学习这些任务的行为，通过一个任务**历史**的行为来推测它**未来**的行为，从而做出应对。

看图：

![[Study Log/os_study/2_virtualization/resources/Pasted image 20240811190133.png|300]]

这个场景里，因为A和B的优先级最高，所以OS只会在AB之间进行RR，C和D完全不会运行。这是暴行！

因此，只知道这些肯定不行，我们需要知道在OS运行过程中，MLFQ是怎么变化的。

### 2.5.2 Attempt \#1: How To Change Priority

首先，就需要知道MLFQ是怎么改变任务的优先级的。记住，我们现在讨论的任务分为两类：

- 交互式任务：运行时间很短，经常释放CPU，但是需要很高的响应速度；
- CPU密集型任务：需要很多CPU资源，但是响应时间不是那么重要。

现在开始讨论如何改变一个任务的优先级。首先，我们看如何降低优先级。我们可以用这个思想：一个任务如果一直运行，一直运行，一直不释放CPU，那这个任务多半是CPU密集型任务。因此我们可以把它的优先级降低。 ^44ccf1

基于这个思想，我们制定出一个概念：allotment。也就是分配时间。如果一个任务运行了一个allotment还在运行，那不好意思，你的优先级要降了。那么allotment是多少呢？简单起见，我们先让他是一个time slice，也就是RR的那个周转时间。

基于此，我们制定这样的规则：

- 当一个任务进入OS，先让它在优先级最高的队列；
- 如果这个任务运行了一个allotment之后还想要运行，那要降低它的优先级，放到下一级队列里；
- 如果这个任务在allotment到达之前主动放弃了CPU（比如进行一个IO），那优先级就仍然保持。

我们来举几个例子。首先是一个一直运行的任务，也就是CPU密集型：

![[Study Log/os_study/2_virtualization/resources/Pasted image 20240811191520.png|300]]

假设allotment是10，这个图很好看懂是吧！不解释了。偶对了，另外还有个假设，就是现在队列中只有这一个任务的时候，才是这样的。如果有其它任务，是不一定能轮得到它运行的。

---

第二个例子。两个任务，一个长的一个短的，**但是都没有IO**：

![[Study Log/os_study/2_virtualization/resources/Pasted image 20240811192131.png|300]]

我们通过这个例子，能看到MLFQ是怎么模拟SJF（准确来说应该是STCF）的。首先T=0的时候，A到达了，一个很长的任务，所以会和第一个例子一样，一直运行，并且优先级变低。

等到T=100的时候，B来了。B刚进来的时候是优先级最高的，所以A被暂停，先运行B。然后B因为一共只有20，所以等T=120的时候B就运行完了，之后A继续运行到结束。

我们也能看出来，MLFQ的主要思想，其实就是[[#^44ccf1|一开始]]说的：我们不知道一个任务是长任务还是短任务。所以我们假设它是一个短的，因此把它放到优先级最高的队列里。如果它真就是一个短的，那么运行一小会儿就结束了。如果运行很长时间（一个allotment）还没结束，那就坏了，这玩意儿不是短的，是长的，所以就会逐渐降低它的优先级。MLFQ就是用这种方式去模拟SJF的。

---

第三个例子：一个长任务，没有IO，和一个有IO的任务：

![[Study Log/os_study/2_virtualization/resources/Pasted image 20240811192902.png|300]]

我们说过，如果任务通过IO放弃了CPU，那要保持高优先级，从而能提高响应时间。结合之前说过的[[Study Log/os_study/2_virtualization/2_4_scheduling_introduction#^976a08|overlap]]，我们可以让一个任务做IO的时候，让CPU去执行另一个，具体方法就是将一个有IO的大任务的每一个小的部分（当然是只利用CPU的部分）看成一个独立的任务。

在这个例子中，T=50的时候任务B来了。但是因为它每隔1就要一个IO，没到达allotment，所以MLFQ会一直保持它的优先级。就这样运行下去。

---

**现在，想想，我们目前的MLFQ有没有缺点**。

其实我在看到上面那几个规则的时候就想到了：怎么优先级只会降低不会提高？那一个任务如果优先级一直低，然后其它那些任务优先级一直很高，那这个任务不就被**饿死**了？

除此之外，在这个简单规则下，一个程序很可能会戏耍MLFQ：我先运行一会儿，等allotment到达之前，发一个IO，然后继续运行。一直重复这种行为，就能一直获取CPU资源。

最后，这种策略还会误杀一些任务。比如一个任务一开始利用很多CPU，导致优先级变低；但是后来它又不怎么用CPU了，反而需要和用户进行交互。那这个时候没有方法把它的优先级升回去，这个任务就很不幸了，不能像其它的交互型任务一样有高优先级。

### 2.5.3 Attempt \#2: The Priority Boost

先试着解决一下starvation的问题。咋解决？很简单，提高优先级呗。我们可以制定一个这样的规则：

- **每经过一段时间S，我们将OS里所有的任务放到优先级最高的队列里。**

这样就能解决了：那些本来会被饿死的任务，因为放到了高优先级队列，总是可以和这个队列里其他的任务进行RR；如果一个CPU密集任务突然变成了交互式任务，我们在提高了优先级之后，它也会被OS处理。

下面是个例子。一共三个任务，一个是长的CPU密集型任务，两个是短的交互式任务。左边是优化前，右边是优化后：

![[Study Log/os_study/2_virtualization/resources/Pasted image 20240820231506.png]]

我们发现，优化之前，那个长的任务从100-200一直得不到执行。就被饿死了；而优化之后，因为会把它放到Q2里，所以起码能稍微分点CPU。

这个优化方法的问题也很明显，就是：***S的值是多少***？如果太大了，那有些优先级很低的任务还是会被饿死；如果太小了，那么那些交互式任务又会“因为频繁有人跑上来跟它抢CPU“导致不能及时被处理。现在，大多数情况是让OS的管理员决定这个值是多少。更激进的办法，还有用类似机器学习的方法来推到出这个值在这个OS上是多少合适：[Automatic Database Management System Tuning Through Large-scale Machine Learning | Proceedings of the 2017 ACM International Conference on Management of Data](https://dl.acm.org/doi/10.1145/3035918.3064029)

### 2.5.4 Attempt \#3: Better Accounting

我们现在先总结一下MLFQ的规则：

1. 优先级高的队列中的任务会先运行；
2. 同一个队列中内部的任务使用Round Robin运行。
3. 当一个任务进入OS，先让它在优先级最高的队列；
4. 如果这个任务运行了一个allotment之后还想要运行，那要降低它的优先级，放到下一级队列里；
5. 如果这个任务在allotment到达之前主动放弃了CPU（比如进行一个IO），那优先级就仍然保持。
6. 每经过一段时间S，我们将OS里所有的任务放到优先级最高的队列里。

我们刚刚加的规则6，解决了之前的两个问题：饿死，和密集型变交互型的问题。但是戏耍OS的问题还没解决。我们来看看是那个规则导致这个问题的：**显然是规则4和规则5**。我们发现，这个戏耍的行为建立在一个基础上，就是：**每次进程发送了一个IO之后，OS就把它已经占用了多长时间CPU这件事，给忘了**。比如一个进程一共占用了100的CPU时间，但是在这中间查了10000个IO操作，每个IO操作都很短很短。那这种行为肯定就是纯纯的戏耍OS。

我们解决这个问题的思路显然就要从“忘记”入手。我们不应该忘记，而是将这个时间进行累加。也就是说：

- **当任务累计运行时间超过一个allotment时，它的优先级就会降低。**

这个规则用来代替原来的规则4和规则5。因此完整的规则如下：

1. 优先级高的队列中的任务会先运行；
2. 同一个队列中内部的任务使用Round Robin运行。
3. 当一个任务进入OS，先让它在优先级最高的队列。
4. 当任务累计运行时间超过一个allotment时，它的优先级就会降低。
5. 每经过一段时间S，我们将OS里所有的任务放到优先级最高的队列里。

还是给一个例子，优化之前和优化之后：

![[Study Log/os_study/2_virtualization/resources/Pasted image 20240821003700.png]]

优化之前，这个灰色的任务一直在戏耍OS，导致黑色的任务根本没咋被执行；而在优化之后，灰色再戏耍OS就没用了。因为你即使一直发IO，累计时间到了也会被降低优先级。等你降低到Q0之后，还是得和黑色的一起RR。

本节其他的内容就是扩展说一说MLFQ。比如有的实现里，会给不同队列中RR不同的time-slice。高优先级的就短，保证更快的调度，低优先级的就长，让一个任务更充分运行。比如还有一些系统，比如FreeBSD，它的调度器中MLFQ的优先级是根据程序使用了多少CPU从而动态算出来的。等等，我们还可以用`nice`命令去手动以某个优先级运行一个任务。

[[Study Log/os_study/0_ostep_index|Return to Index]]