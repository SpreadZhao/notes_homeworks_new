## 2.3 Mechanism: Limited Direct Execution

想虚拟化CPU，底层原理其实很简单：运行一小会儿这个程序，然后运行一小会儿那个……但是这样操作会带来很多问题。最重要的两个问题：

- performance：实现这样的虚拟化必须保证性能，尽可能少带来额外开销；
- control：必须在OS的控制下，比如一个进程不能随便获取CPU资源。

要实现这个，硬件和软件（OS）都是需要的。

### 2.3.1 Basic Technique: Limited Direct Execution

为了实现这些，OS的开发者提出了一个概念叫Limited Direct Execution。我们先解释什么是Direct Execution。非常简单，就是直接让程序运行在CPU上。当程序开始运行时，OS就需要做下面的事情：

| OS                       | Program  |
| ------------------------ | -------- |
| 在进程列表中创建当前进程的项目          |          |
| 给进程分配内存                  |          |
| 把程序从磁盘加载到内存中             |          |
| 设置好程序的栈空间（通过argc / argv） |          |
| 清除寄存器                    |          |
| 开始调用程序的main函数            |          |
|                          | main开始运行 |
|                          | main返回   |
| 释放程序的内存                  |          |
| 把程序从进程列表中删除              |          |

^90c713

很简单，但是带来两个问题：

1. 太简单了，没办法保证程序在运行的时候不会干什么坏事——2.3.2；
2. 运行一个进程的时候，怎么停下来运行另一个进程，从而实现time-sharing——2.3.3。

### 2.3.2 Problem \#1: Restricted Operations

如果一个进程想要做比如

- 处理磁盘的IO请求；
- 获取更多系统资源（比如CPU）

这样需要限制的行为，作为OS来说应该怎么办？

最简单的办法：**您随便折腾**。也就是允许进程做任何想做的事情。但是这样肯定是不安全的。比如进程想要访问**一个文件**的时候，OS要检查权限。但是这个时候如果OS直接说：啊，你要访问文件啊，那文件系统你随便用吧！简单是简单，也能实现功能，但是也太不安全了。进程只想访问一个文件，但是你把整个文件系统的读写都交给它了。

OS解决这个问题的办法是，引入**用户态**（user mode）和**内核态**（kernel mode）。在用户态，进程根本就不允许发送IO请求。你要是发送了，后果就是进程直接异常，被OS干掉；而在内核态，这些代码就随便了，比如IO请求，其它的有限制的代码都能运行。

那这样的问题显而易见：我进程还不让读文件了？凭啥？因此，我们必须让用户态的程序也能执行一些有限制的指令。这个问题的解决方式就是**系统调用**（system call）。**系统调用是内核很小心地暴露出来的一小部分功能**，给用户态的进程去用。比如访问文件系统，和其它进程通信，分配更多内存等等。

> [!note]
> 我们[[Study Log/os_study/2_virtualization/2_2_process_api|上一节]]介绍的东西就都是系统调用。这里再说一下我对系统调用的理解。
> 
> 我们直接说汇编，因为和真正的机器指令是最像的。假设根本没有操作系统，我们编写的程序应该是怎样的？显然，就是一些计算，对内存的读取，对寄存器的读取，对IO设备的访问等等。那么这些指令是可以随便执行的吗？显然不是。比如内存，如果直接调用LEA指令就能加载内存中任意地址的数据，那不是整个系统（虽然没有系统，但是就这么说了）里所有的数据我都有了？即使不是我这个进程的。那操作系统里引入系统调用最根本的目的，就是将这些不能给人随便执行的指令封装起来，并且不能让用户态的进程随便使用，必须是加以严格限制，按照规范来使用。

为了执行系统调用，程序必须执行一个**trap**指令。该指令能让程序从用户态陷入到内核态，从而执行内核态的代码。执行完毕后，再执行一个**return-from-trap**指令回到用户态。

> [!attention]
> 本人认为，以下所说的硬件可以认为就是CPU。当然可能也包括一些CPU和内存，IO设备等配合完成的工作。

硬件在trap执行的时候需要做一些安全保障工作，以便从内核态返回时，程序的一些寄存器等能正常工作。比如在x86上，处理器会把PC指针，一些标记位，还有其它的一些寄存器保存到一个**内核栈**（kernel stack）里。这玩意儿是每个进程都有一个的。 

还有一个问题：trap是怎么知道运行哪段代码的？显然，这个代码的地址肯定不是让用户态的进程去指定的。比如打开文件的这个open，实际上我们不是通过调用`syscall(0x123456)`之类的方式。如果`0x123456`里的代码真就是open在内核中对应的系统调用的代码的地址，那么我完全可以传入一个随便的地址，甚至可以通过很多**邪恶**的手段执行任意代码（比如可以通过一个偏移量直接定位到一行代码，然后再这样，一点点拼成自己想执行的恶意程序）。

OS解决这个问题的方式是通过**trap table**。当开机的时候，OS首先要做的事情就是：**当特定的事件发生的时候，硬件应该做什么**。比如硬盘的中断产生的时候做什么，键盘中断的时候做什么，一个进程发送一个系统调用的时候做什么等。这里的“做什么”具体来讲，就是一个函数，叫做**trap handler**。也就是陷入内核的处理者。<fieldset class="inline"><legend class="small">💬</legend>OS设置好trap table</fieldset>，并告知给硬件们，这样直到下一次启动之前，硬件都知道应该做什么了。 ^bf8972

> [!comment] OS设置好trap table
> 从这里也能看出，地址是随机的，这样攻击的程序就不能随便指定地址了。另外顺便说一下，trap handler其实就是系统调用的函数。只不过在前面会先进行一个==验证==。

那既然地址是随机的？对于用户程序来说，我怎么知道发送哪个系统调用呢？答案是通过**系统调用号**（system-call number）。当trap进内核态，进行系统调用的时候，==先看这个号是否有效==，然后去执行对应的代码。这样就起到了保护作用，用户态程序只能通过调用号来执行对应的系统调用，但是不能跳到特定的地址上。地址也根本不会暴露出去（我瞎说的，存疑）。

> [!question] 为什么系统调用看起来那么像普通函数调用？
> 比如`open()`和`read()`，就和我们在C里自己写的函数没啥区别。那既然这样的话，凭啥OS认为这东西就是系统调用，我们自己写的函数就不是系统调用呢？实际上，系统调用的这些函数本身没有什么特殊的，特殊的是在函数里隐藏的trap指令。详细点儿说，当我们调用open的时候，就是调用到C标准库，和其他的函数没啥区别。但是特殊在库里面，会把open的参数放到一个特定的位置（比如在栈上或者特殊的寄存器里），也会把系统调用的调用号放到那里，然后开始执行trap指令。执行完trap之后，就是处理返回值，然后把控制权交回给用户态的程序。因此，这一段代码是用汇编硬编码在C标准库里的。

最后，OS设置trap table的这个行为，也就是告诉硬件trap table在那里这个指令本身肯定也是一个有权限的指令，只能由内核来做。

> [!tip] 警惕用户的输入！
> 我们现在做的关于安全的东西：
> 
> - 加了一个trap机制，让硬件来陷入内核；
> - 确保所有的关于OS的核心代码的执行都要通过trap机制。
> 
> 但是，距离真正的安全系统还是差得远。比如，系统调用里传入的这个参数，我们就得好好检查一下。
> 
> 比如，write系统调用可以往地址里写东西。那如果我传入了一段内核空间的地址，然后你还让我写，那可毁了。这段地址有可能包括真正的物理内存。这甚至会让这个程序能读系统上运行的所有程序的内存。

我们来总结一下trap机制去执行系统调用的时间线（下面的总结里假设每个进程都有个内核栈空间，用于保存寄存器和PC指针）：

![[Study Log/os_study/2_virtualization/resources/Drawing 2024-07-02 16.55.14.excalidraw.svg]]

十分建议和[[#^90c713|之前的表格]]对比着读。LDE的执行分成两个阶段。第一个是启动（boot）阶段，内核会初始化trap table，CPU会记住它的地址（当然也包括trap handler）为了接下来处理系统调用。初始化工作也是一个有权限才能执行的指令（上图标红的都是有权限才能执行的）。在程序启动前，也会调用一个return-from-trap指令来切换到用户态。这个是之前的表格中没有提到的事情。当程序运行结束之后，调用exit系统调用来退出程序。这也会导致陷入内核态，因为要处理内存释放、删除process list entry等操作。

### 2.3.3 Problem \#2: Switching Between Processes

我们现在的策略是time-sharing，也就是CPU会运行一会儿这个程序，再运行一会儿那个。那这里背后其实隐藏着一个比较致命的bug：**OS本身也是程序**。那如果我切换到了随便一个进程去运行，**这个时候OS就不在运行了**。那既然OS都没运行，它又怎么能切换进程？

#### 2.3.3.1 A Cooperative Approach: Wait For System Calls

这种方式在老式的OS（Macintosh的老版本，或者老的Xerox Alto系统）上有，因为听着就挺玄乎：等着进程发送系统调用，这样我就能重新获得控制权。显然，这种策略是很passive的。

这种策略建立在OS对进程的信任上：进程如果在CPU上运行了太长时间，自己就会主动放弃CPU的使用权从而交给其他人。放弃的方式就是通过系统调用。普通的系统调用比如open，write等当然也可以做这件事，但是显得比较随便。所以这样的OS通常都会给你一个额外的系统调用**yield**来做这件事。yield不会做任何其他的事情，只是用于将控制权交还给CPU而已。

- [ ] #TODO tasktodo1719926008742 java线程也有yield，功能类似，但是好像不常用；POSIX Thread是不是也应该有这个东西？之后有时间看一看。 ➕ 2024-07-02 🔽 🆔 8shvfk

当程序进行一些非法行为的时候，也会把控制权交给OS。比如，来个0做除数的计算，或者访问一些非法内存的时候，也会执行一个trap指令。这个时候OS会重新获得控制权，然后很可能就把这个进程给干掉了。

总结，被动，很不靠谱。如果一个进程一直不发送系统调用，比如直接死循环了，那咋办？

#### 2.3.3.2 A Non-Cooperative Approach: The OS Takes Control

如果一个进程就是不发送系统调用，那我应该怎么办？解决方法很久之前就有很多人发现了：**既然你进程不配合，我就找个专门的人来配合**。在这些系统中有个专门的timer设备，会以固定的频率发送timer interrupt。当这种中断产生时，进程就会暂停运行，然后OS内部预先准备好的interrupt handler就会运行。这个时候OS就重新获得控制权，就可以切换进程了。

就像我们[[#^bf8972|之前]]讨论的，OS必须告诉硬件当某些特定事件发生时应该做什么。timer就是其中一个。当timer interrupt产生时，OS也需要处理对应的事件。所以它也要告诉CPU；另外，开机的时候，OS也必须要启动timer，当然这也是一个有权限的指令。然后，不管怎么样，OS最终都会得到控制权了。另外，timer也可以关闭，这个我们之后学并发的时候会提到。

- [ ] #TODO tasktodo1719929090619 ↑ timer可以关闭提到了吗？ ➕ 2024-07-02 🔽 🆔 ok57rm

注意，timer interrupt的处理方式和trap很像，都是需要硬件去保存特定的寄存器，也就是保存现场，之后return-from-trap的时候之前挂起的程序才能恢复运行。

> [!note]
> 这里说一下我对trap这种模式的理解，为什么硬件需要参与。实际上，所有的程序都需要运行在CPU上，OS也不例外，它也是一堆程序组成的，也需要运行在CPU上。拿[[Study Log/os_study/2_virtualization/resources/Drawing 2024-07-02 16.55.14.excalidraw.svg|之前的表格]]来举例子，从左到右就是一个『软-硬-软』的结构。但是实际上**两个软**的内容最终也都要运行在**这个硬**上。而硬里面运行的内容，比如保存寄存器到内核栈等等，这些指令本身也是运行在硬上的。之所以要分成三列，主要是取决于“谁对这段代码**负责**”，而不是“谁**运行**这段代码”。程序员写的用户态进程也运行在CPU上，但是程序员，也就是用户态要对它进行负责，所以才写到第三列。
> 
> 而OS在这里的特殊性，或者说内核态的特殊性，是在软件层面上规定谁来运行程序，也就是谁使用CPU。因此，OS当然有权利直接在CPU上运行指令，其实任何一个进程都可以，只不过OS在内核态，所以能运行一些有特权的指令来保证系统正常工作。

#### 2.3.3.3 Saving and Restoring Context

OS重新获得控制权之后，需要做决定了：是继续运行当前程序，还是运行其它的。做这件事的是OS内部的调度器（scheduler），之后我们会详细讨论。

如果确定要切换进程的话，OS就会执行一系列代码，叫做**上下文切换**（context switch）。具体工作也很简单，就是保存当前进程的寄存器，尝试恢复即将运行的进程的寄存器。具体过程如下：

![[Study Log/os_study/2_virtualization/resources/Drawing 2024-07-02 22.59.22.excalidraw.svg]]

注意点：

- 当timer interrupt产生时，需要切换到内核态，让OS重新夺回CPU使用权；
- 在切换到内核态之前，要保存当前进程（A）的寄存器，到A的**内核栈**；
- 当OS获得了控制权之后，它**决定**（通过schedulor）从A切换到B；
- OS调用`switch()`来切换上下文；
- `switch()`所做的事情：
	- 保存A的寄存器到A的[[Study Log/os_study/2_virtualization/2_1_process#^ad384f|进程结构]]；
	- 恢复B的寄存器，从B的进程结构；
	- 进行上下文切换：通过将stack pointer指向B的内核栈（原来是指向A的）；
- 我们发现，硬件和OS都进行了保存/恢复寄存器的操作。这两个东西的目的是不同的：
	- CPU保存/恢复的是**user registers**，地点是进程的内核栈；
	- OS保存/恢复的是**kernel registers**，地点是进程的结构；
	- **OS的这个操作能使得系统好像是刚经过$B \xrightarrow{trap\ into} kernel$一样，即使事实情况是$A \xrightarrow{trap\ into} kernel$**。

xv6内核中上下文切换的代码：[.globl swtch swtch: movl 4(%esp), %eax movl 8(%esp), %edx # Save old callee-saved registers pushl %ebp pushl %ebx pushl %esi pushl %edi # Switch stacks movl %esp, (%eax) movl %edx, %esp # Load new callee-saved registers popl %edi popl %esi popl %ebx popl %ebp ret](https://github.com/mit-pdos/xv6-public/blob/master/swtch.S)

```asm
# Context switch
#
#   void swtch(struct context **old, struct context *new);
# 
# Save the current registers on the stack, creating
# a struct context, and save its address in *old.
# Switch stacks to new and pop previously-saved registers.

.globl swtch
swtch:
  movl 4(%esp), %eax
  movl 8(%esp), %edx

  # Save old callee-saved registers
  pushl %ebp
  pushl %ebx
  pushl %esi
  pushl %edi

  # Switch stacks
  movl %esp, (%eax)
  movl %edx, %esp

  # Load new callee-saved registers
  popl %edi
  popl %esi
  popl %ebx
  popl %ebp
  ret
```