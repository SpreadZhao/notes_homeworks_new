# 1. 前言

本次上机结束后，我的感受就是：明明都是感觉很简单的问题，但是就是死活弄不出来。好在工作量整体比第一次实验少很多，所以只用了5个多小时就完成了。即使是这样，在一开始我也是走了一个大弯路，导致最后需要从头再来。因此实验内容的部分也分成了两段：失败经历和成功经历。

# 2. 实验名称

第二次实验：HBase的安装与配置

# 3. 实验日期

2022年10月12日    宿舍

# 4. 实验学生

20009200303 赵传博

# 5. 实验内容

* 在Hadoop的基础上，配置HBase环境
* 使用HBase的Shell命令操作数据库

# 6. 失败经历

## 6.1 版本检查

hadoop和hbase需要配合使用，因此我们先检查一下它们俩的版本搭不搭。我们在官网就能看到版本对应信息的表格：

![[Pasted image 20221012221433.png]]

本次我们选择的是Hadoop-3.3.4和HBase-2.4.14，它们正好符合官方的要求。

## 6.2 环境变量

接下来开始配置环境变量，由于只有一个软件，所以非常简单。只需要把它们加入到之前配置Hadoop时创建的`/etc/bashrc`中即可：

```shell
echo "export HBASE_HOME=/home/work/_app/hbase-2.4.14" >> /etc/bashrc
echo "export PATH=\$PATH:\$HBASE_HOME/bin" >> /etc/bashrc
```

然后再执行source命令，就能够随时让所有的软件待命了。配置变量的同时，**别忘了把软件包下载到对应的目录**！也就是`/home/work/_app/hbase-2.4.14`。

接下来，按照例行是需要检测一下我们的环境变量配没配好。使用如下命令来查看：

```shell
hbase version
```

如果正常输出版本信息，就表明成功了。但是我却看到了如下信息：

![[Pasted image 20221012222011.png]]

可以看到，是由于两个jar包冲突导致无法正确绑定，因此我毫不犹豫删除了其中一个： ^8e715c

```shell
rm /home/work/_app/hbase-2.4.14/lib/client-facing-thirdparty/slf4j-reload4j-1.7.33.jar
```

接下来，就可以正确输出版本信息了：

![[Pasted image 20221012222208.png]]

**但是这个操作，也成为了接下来让我头大的一个操作。**

## 6.3 HBase族群配置

这部分对应[[1. hadoop#6 13 Hadoop设置|第一次实验的Hadoop设置]]，并且内容都很相似。首先打开`/home/work/_app/hbase-2.4.14`这个根目录(以下记为`<hbRoot>`)下的`conf/`目录，然后编辑其中的`hbase-env.sh`文件，将其中的几项修改成这样： ^706f2d

```shell
export JAVA_HOME=/opt/openlogic-openjdk-8u342-b07-linux-x64
# 是否使用内置zookeeper。默认false，也就是不使用
export HBASE_MANAGES_ZK=true
export HBASE_PID_DIR=/var/hadoop/pids
```

^bbefd4

然后我们就可以将HBase连带着配好的文件还有环境变量一同发送给slave们了：

```shell
for slave in slave1 slave2; do scp /etc/bashrc spreadzhao@$slave:/etc/bashrc; done
for slave in slave1 slave2; do scp -r hbase-2.4.14 spreadzhao@$slave:/home/work/_app; done
```

接下来我们需要对master结点开点小灶，配置好Hbase的核心。打开`hbase-site.xml`，将配置中的property替换成如下内容： ^7d1c45

```xml
<property>
<!-- hbase的根目录，我们搭配hadoop使用，所以放到hdfs中 -->
	<name>hbase.rootdir</name>
	<value>hdfs://master:9000/hbase</value>
</property>

<property>
	<name>hbase.cluster.distributed</name>
	<value>true</value>
</property>

<property>
	<name>hbase.zookeeper.property.dataDir</name>
	<value>/home/work/_data/zookeeper-3.8.0/zkData</value>
</property>

<property>
	<name>hbase.zookeeper.quorum</name>
	<value>master:2181,slave1:2181,slave2:2181</value>
</property>

<property>
	<name>hbase.zookeeper.property.clientPort</name>
	<value>2181</value>
</property>
```

然后对于两个slave，`hbase-site.xml`中只需要如下内容就可以了：

```xml
<property>
	<name>hbase.rootdir</name>
	<value>hdfs://master:9000/hbase</value>
</property>

<property>
	<name>hbase.cluster.distributed</name>
	<value>true</value>
</property>
```

然后配置`regionservers`，这是所有干活儿的服务器： ^1c1937

```
slave1
slave2
```

## 6.4 失败！

到这里其实就已经配置完成了。我们只需要执行`start-dfs.sh`和`start-hbase.sh`就可以正常使用hbase了。但是，在开启hbase的时候却出现了许多错误。

![[Pasted image 20221012224458.png]]

![[Pasted image 20221012224539.png]]

其实hbase这时已经启动了，可以使用shell命令进入hbase的操控：

```shell
hbase shell
```

但是在里面使用`status`查看状态时，毫无疑问是失败的： ^05deb6

![[Pasted image 20221012224658.png]]

首先我更改了[[#^706f2d|这里]]的`HBASE_PID_DIR`，因为这里显示没有权限，那就改成有权限的：

```shell
export HBASE_PID_DIR=/home/work/_data/hbase-2.4.14/hadoop/pids
```

这里新建了一个文件夹用来存放pid。之后将它发送到所有结点。

之后再启动的时候，确实不会显示无法创建了。但是更大的问题还在后面：

![[Pasted image 20221012225324.png]]

这一个个的错误看得我眼花缭乱。但是我还是注意到了前面的`SLF4J`。这貌似和我[[#^8e715c|之前]]删除的一个包有关。因此我就开始了一系列看起来没啥用，实际上也没啥用，但是让我很闹心的操作：恢复hbase的jar、只删掉hadoop的jar，将两个jar改成同一个版本，在两个终端使用不同的环境变量(因为我当时猜测可能是环境变量导致了它们引用了同一个包。所以我在`start-dfs.sh`之后重启了终端，并只将hbase的环境变量引用。不过这明没有什么卵用)……最终还是状况依旧。

---

后来，我找到一篇文章有提到，在`hbase-env.sh`中还有这样的一个命令：

```shell
export HBASE_DISABLE_HADOOP_CLASSPATH_LOOKUP="true"
```

这条命令配置的是hbase是否禁用hadoop的classpath。当为true时，hbase就不再会引用classpath的环境变量，默认为`false`。当我修改完之后并发送到所有节点后，还是一样的结果。这令我很失望，令我很**愤怒**！！！！！于是，我果断准备重开，并且最终不负众望，成功配置了hbase。但是，**这条命令对于最后的成功确实是有用的**。 ^6f5cc2

# 7. 成功经历

## 7.1 准备重开

我们之前做的不可能都是无用功，所以首先要把最重要最繁琐的部分保存下来，在接下来重开的过程中就会简单很多。其实只有`hbase-env.sh`和`hbase-site.xml`这两个文件是需要有较大改动的，其它的文件并没有很重要。

然后，**删除所有结点的`/home/work/_app/hbase-2.4.14`文件夹！**是时候和过去说再见了。

## 7.2 重新配置族群

重新将压缩包拷贝到master中，并编辑`hbase-env.sh`文件：

```shell
export JAVA_HOME=/opt/openlogic-openjdk-8u342-b07-linux-x64
export HBASE_MANAGES_ZK=true
export HBASE_PID_DIR=/home/work/_data/hbase-2.4.14/hadoop/pids
```

然后编辑`hbase-site.xml`文件：

```xml
<property>
	<name>hbase.rootdir</name>
	<value>hdfs://master:9000/hbase</value>
</property>

<property>
	<name>hbase.cluster.distributed</name>
	<value>true</value>
</property>

<property>
	<name>hbase.zookeeper.property.dataDir</name>
	<value>/home/work/_data/hbase-2.4.14/zkData</value>
</property>

<property>
	<name>hbase.zookeeper.quorum</name>
	<value>master,slave1,slave2</value>
</property>
```

这个版本的文件和之前相比，有3个改动：

* 将`dataDir`改成了hbase目录下的新建文件夹`zkData/`，因为我们已经[[#^bbefd4|使用内置的zookeeper]]了，所以`dataDir`自然不能放在zookeeper里了。
* 将`quorum`中的端口删掉，这可能是新版本的方法，也就是官网上写的。不过加上端口可能也没有什么问题。
* 删掉监听端口的property。我觉得这个影响也不大，不过做到最简总有好处。

> 由于hbase-site.xml中所有项都有默认值，因此我们能省略很多东西，这里只是添加了分布式环境必要的一些配置，比如配合hadoop的文件系统。其实在单机模式下使用这些配置都不用写。

然后我们将整个hbase文件夹都scp到所有结点。这和[[#^7d1c45|之前]]的操作也不同。

## 7.3 启动HBase

然后我们就可以开心地启动HBase了。这次很正常，没有报任何错！这也正是[[#^6f5cc2|那条命令]]的作用。

![[Pasted image 20221012232537.png]]

> 可能是我眼睛有问题，没看到那个`4 dead`吧。。。

这个时候再使用`status`查看状态，哎~，还是错了：

![[Pasted image 20221012232707.png]]

## 7.4 修理"小"问题

似乎，我们有一个文件没有配置就着急启动了。那就是[[#^1c1937|regionservers]]。我们还是只修改master结点中的内容：

```
slave1
slave2
```

两个slave上只留下：

```
localhost
```

我猜测一下其中的原因：这个文件是指：我这个结点认为server都是谁。所以master结点认为server是两个slave；而两个slave认为server是它们自己。这样正好符合hbase的结构描述。

这下终于可以正常查看`status`了：

![[Pasted image 20221012233211.png]]

但是在创建表的时候又错了！！！

![[Pasted image 20221012233233.png]]

首先，我考虑了是否是时间同步的问题，因此将三台机器都同步上亚洲时间并写入硬件：

```shell
sudo ntpdate 0.asia.pool.ntp.org
sudo hwclock --systohc
```

然后，再将zookeeper和hdfs所有关于hbase的信息都删除，这样才能真正重新来过。首先进入hbase自带的zookeeper：

```shell
hbase zkcli
```

然后执行如下命令，删掉`/hbase`：

![[Pasted image 20221012234500.png]]

然后将hbase关掉：

```shell
stop-hbase.sh
```

之后将hdfs中的hbase也删掉：

```shell
hdfs dfs -rm -r /hbase
```

最后重新打开hbase，一切终于成功！

![[Pasted image 20221012234650.png]]

![[Pasted image 20221012234725.png]]

另外还有一个小点，在执行`stop-hbase.sh`关闭的时候经常会出现一直闪`...`却关不掉的情况。这个时候先执行`hbase-daemon.sh stop master`关闭主结点，之后再关闭hbase就能关掉了。

# 8. 总结建议

本次实验的报告字数只有第一次的三分之一，但是我经历的绝望却比第一次多很多很多。比如所有实验都完成后，再启动hbase又出现了[[#^05deb6|之前]]的情况，但是关掉再重启一次后又能用了。其实我还是感觉这个hbase的配置并不完整，不过最起码，我算是完成了这项看起来很简单的任务。从开始实验到报告写完，也只用了不到9个小时，效率还是蛮高的~O(∩_∩)O

使用hbase的语句就不展示在这里了，等后期好好了解它和MySQL这种关系型数据库的区别之后，再着手研究(咕咕咕~)。