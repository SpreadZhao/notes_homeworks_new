**王学长写的qemu的cpu模拟，主要介绍Tiny Code Generator**

qemu_TCG ---------动态翻译器

# 1 介绍

kvm：https://en.wikipedia.org/wiki/Kernel-based_Virtual_Machine基于内核的虚拟机**( **KVM ) 是Linux 内核中的一个虚拟化模块，它允许内核充当管理程序。它在 2007 年 2 月 5 日发布的 2.6.20 版本中被合并到主线 Linux 内核中。需要具有硬件虚拟化扩展的处理器，例如[Intel VT](https://en.wikipedia.org/wiki/Intel_VT)或[AMD-V](https://en.wikipedia.org/wiki/AMD-V)。可以直接在host上运行guest指令！所以很快，基本上跟直接运行没什么区别，可能稍微慢那么一点点。

tcg：很慢，用它加速Ubuntu21.04，开机用了2个小时。而使用同样参数（内存大小和cpu数量）的kvm加速就很快。

PowerPC没有kvm。TCG是由qemu开发的，它虽然慢，但是它能跨平台。

以下内容为PowerPC到x86的转换。

这里祭出一张流程图，非常重要。（虽然已经与现版本有一点区别，但是基本流程是一样的）

![[cpusi.jpg]]

从这张图中可以看到cpu的模拟过程-----------翻译与执行循环。

上面流程图中的最左侧就不谈了，通过GDB打断点看bt就可以了，实际情况和左侧图有一点区别。从第二个框开始，cpu_exec()为cpu执行函数，cpu_exec()里面有一个tb_find()函数，tb_find()函数会寻找TB(translate block) buffer，TB buffer里面存着已经翻译好的指令（二进制），如果buffer里面有，就执行，跳到cpu_tb_exec()函数，如果没有，就调用tb_gen_code()生成。

生成就是流程图中的右侧的函数了，分为两个部分，guest指令翻译成中间码，中间码翻译成host指令，生成的host指令就存到一个buffer里面，跳到cpu_tb_exec()函数执行。

这个流程图基本就这个意思，后面分析细节。

# 2 翻译

## 2.1tb_find()

以下内容按照函数调用顺序分析，展示的代码只留关键函数。

两个关键函数tb_find()和cpu_loop_exec_tb()，tb_find()用于翻译，cpu_loop_exec_tb()用于执行。(代码位置：accel/tcg/cpu-exec.c)

```c
int cpu_exec(CPUState *cpu)
{
    (...)    
        while (!cpu_handle_interrupt(cpu, &last_tb)) {
         	(...)
            tb = tb_find(cpu, last_tb, tb_exit, cflags);
            cpu_loop_exec_tb(cpu, tb, &last_tb, &tb_exit);
          
        }
    }
    return ret;
}
```

首先来看tb_find()函数，cpu_loop_exec_tb()放在执行章节来讲。(代码位置：accel/tcg/cpu-exec.c)

```c
static inline TranslationBlock *tb_find(CPUState *cpu,
                                        TranslationBlock *last_tb,
                                        int tb_exit, uint32_t cf_mask)
{
    if (tb == NULL) {     
        tb = tb_gen_code(cpu, pc, cs_base, flags, cf_mask);       
    }
    return tb;
}
```

如果tb_find()函数没有找到TB，就会调用tb_gen_code函数来进行翻译。首先将guest指令翻译成中间码（TCG ops），通过gen_intermediate_code()函数，然后将中间码翻译成host指令。

```c
TranslationBlock *tb_gen_code(CPUState *cpu,
                              target_ulong pc, target_ulong cs_base,
                              uint32_t flags, int cflags)
{
	（...）
    gen_intermediate_code(cpu, tb, max_insns);
	(...)
    gen_code_size = tcg_gen_code(tcg_ctx, tb);
 	(...) 
}
```

## 2.2 gen_intermediate_code()

首先解释target，target代表模拟的架构，在这里是PowerPC，所以涉及翻译第一个阶段的文件放target文件夹下，本文的情况是target\ppc。但是target会引起歧义，后面就会看到原因，所以我们用guest表示，本文的情况是guest--->PowerPC ，host--->x86。PowerPC为要模拟的架构，x86为我们自己的架构。

gen_intermediate_code()函数会调用translator_loop()函数：

`translator_loop(&ppc_tr_ops, &ctx.base, cs, tb, max_insns);`

其中的输入`&ppc_tr_ops`，是`TranslatorOps ppc_tr_ops`。

该 `gen_intermediate_code`函数是`translator_loop`通用函数的依赖于 VM 架构的包装器 。这个不明白的话，自己看一下源码就明白了。就是有很多 `gen_intermediate_code`函数，如下图所示，不同的架构有不同的`gen_intermediate_code`函数，但是都会调用`translator_loop`通用函数。

![[gen_intermediate_code.png]]

比如我们在 Intel x86 主机上模拟 PowerPC 代码。调用的就是`target/ppc`文件夹下的`gen_intermediate_code`函数。`translator_loop`函数对于所有架构都是一样的，所以叫通用函数。虽然 `translator_loop` 对于任何架构来说都是一样的，但它依赖于目标特定的 `翻译操作符`。在我们的例子中，是PowerPC 的 ( `ppc_tr_ops`)。

 可以看到`translator_loop`函数有一个输入是`const TranslatorOps *ops`，不同架构，ops是不一样的。TranslatorOps是一个结构体，里面声明了函数，不同架构指明了对应的函数，在`translator_loop`函数中用指针调用需要的成员函数。

```c
void gen_intermediate_code(CPUState *cs, TranslationBlock *tb, int max_insns)
{
    DisasContext ctx;

    translator_loop(&ppc_tr_ops, &ctx.base, cs, tb, max_insns);
}
```

```c
void translator_loop(const TranslatorOps *ops, DisasContextBase *db,
                     CPUState *cpu, TranslationBlock *tb, int max_insns)
{
    ops->init_disas_context(db, cpu)
    gen_tb_start(db->tb);           
    ops->tb_start(db, cpu);       
    while (true) {
        ops->insn_start(db, cpu);     
        ops->translate_insn(db, cpu);  
    }
    ops->tb_stop(db, cpu);   
    gen_tb_end(db->tb, db->num_insns - bp_insn); 
}
```

下面展示了结构体TranslatorOps，以及PowerPC的TranslatorOps ppc_tr_ops。

```c
//（代码位置：target/ppc）
typedef struct TranslatorOps {
    void (*init_disas_context)(DisasContextBase *db, CPUState *cpu);
    void (*tb_start)(DisasContextBase *db, CPUState *cpu);
    void (*insn_start)(DisasContextBase *db, CPUState *cpu);
    bool (*breakpoint_check)(DisasContextBase *db, CPUState *cpu,
                             const CPUBreakpoint *bp);
    void (*translate_insn)(DisasContextBase *db, CPUState *cpu);
    void (*tb_stop)(DisasContextBase *db, CPUState *cpu);
    void (*disas_log)(const DisasContextBase *db, CPUState *cpu);
} TranslatorOps;
static const TranslatorOps ppc_tr_ops = {
    .init_disas_context = ppc_tr_init_disas_context,
    .tb_start           = ppc_tr_tb_start,
    .insn_start         = ppc_tr_insn_start,
    .breakpoint_check   = ppc_tr_breakpoint_check,
    .translate_insn     = ppc_tr_translate_insn,
    .tb_stop            = ppc_tr_tb_stop,
    .disas_log          = ppc_tr_disas_log,
};
```

- `.init_disas_context`初始化 DisasContext 结构的PowerPC的部分。主要用于将记录当前的 cpu 状态信息，通用 DisasContextBase 已经初始化。
- `.tb_start`在主循环开始之前，通用 gen_tb_start() 之后发出任何所需的代码。此函数实际为空
- `.insn_start`发出 tcg_gen_insn_start 操作码。tcg_gen_insn_start操作码作为标志，代表翻译的指令的开始，一个ppc指令可能翻译成多个IR，tcg_gen_insn_start操作码作为分割标志。
- `.breakpoint_check`当此函数调用时，断点被检查以匹配 PC，但target可能会导致断点错过了地址（例如，由于在其标志中编码的条件）。返回 true 表示断点确实命中，在这种情况下不再检查断点。如果断点确实命中，则发出发出异常信号所需代码，并根据需要设置 db->is_jmp 以终止主循环。
- `.translate_insn`反汇编一条指令，设置db->pc_next 为下一条指令的开始。根据需要设置 db->is_jmp 以终止主循环。insn代表instruction
- `.tb_stop`根据 db->is_jmp 发出退出 TB 所需的任何操作码。
- `.disas_log`打印指令反汇编到日志。

下面分析translator_loop()函数

```c
void translator_loop(const TranslatorOps *ops, DisasContextBase *db,
                     CPUState *cpu, TranslationBlock *tb, int max_insns)
{
    ops->init_disas_context(db, cpu);   //调用ppc_tr_init_disas_context函数
...
    gen_tb_start(db->tb);            //通用TB生成，并检查指令计数和退出条件
    ops->tb_start(db, cpu);          //调用ppc_tr_tb_start函数

    while (true) {
        ops->insn_start(db, cpu);     //调用ppc_tr_insn_start函数
        ops->translate_insn(db, cpu);  //调用ppc_tr_translate_insn函数
    }
...
    ops->tb_stop(db, cpu);    //调用ppc_tr_tb_stop函数
    gen_tb_end(db->tb, db->num_insns - bp_insn); //退出 TB
}
```

- `gen_tb_start(db->tb)`生成tb,它注入指令以检查指令计数和退出条件。
- `ops->tb_start(db, cpu)`代表当前块，开始翻译指令，实际为空
- `ops->translate_insn(db, cpu)`用于将目标指令转换为 IR 
- `gen_tb_end()` 它注入指令以退出 TB ( `tcg_gen_exit_tb`)

 用于将target指令转换为 IR 的函数是 `translate_insn` (对于 PowerPC来说是`ppc_tr_translate_insn`)。此函数利用target CPU `opcodes`处理程序表，该表为每个target指令实现 IR 生成。 （target/ppc/translate.c）

```c
static void ppc_tr_translate_insn(DisasContextBase *dcbase, CPUState *cs)
{
    opc_handler_t **table, *handler;

    table = cpu->opcodes;
    handler = table[opc1(ctx->opcode)];
...
    (*(handler->handler))(ctx);
}

struct PowerPCCPU {
...
  
    opc_handler_t *opcodes[PPC_CPU_OPCODES_LEN];
...
}

static opcode_t opcodes[] = {
GEN_HANDLER(cmp, 0x1F, 0x00, 0x00, 0x00400000, PPC_INTEGER),
GEN_HANDLER(cmpi, 0x0B, 0xFF, 0xFF, 0x00400000, PPC_INTEGER),
GEN_HANDLER(cmpl, 0x1F, 0x00, 0x01, 0x00400001, PPC_INTEGER),
...
GEN_LDS(lbz, ld8u, 0x02, PPC_INTEGER)
GEN_LDS(lha, ld16s, 0x0A, PPC_INTEGER)
...
};
```

在opcodes[]中找到形如GEN_的函数

```c
static opcode_t opcodes[] = {
...
GEN_STS(stw, st32, 0x04, PPC_INTEGER)
...
};
```

然后根据#define GEN_ST找到gen_的处理函数

```c
#define GEN_ST(name, stop, opc, type)                        \
  GEN_HANDLER(name, opc, 0xFF, 0xFF, 0x00000000, type),

#define GEN_HANDLER(name, opc1, opc2, opc3, inval, type)     \
  GEN_OPCODE(name, opc1, opc2, opc3, inval, type, PPC_NONE)
```

然后找到tcg_gen_qemu_函数，有一个发出的 IR  INDEX_op_qemu_st_i32 操作码，第一个过程结束（tcg/tcg-op.c）

tcg_gen_* 的用户不需要知道任何内部这些的细节，并应将它们视为不透明类型。 您也无法在调试器中查看它们的内部。

```c
void  tcg_gen_qemu_st_i32 (TCGv_i32 val, TCGv addr, TCGArg idx, TCGMemOp memop) 
{ 
... gen_ldst_i32 (INDEX_op_qemu_st_i32, val, addr, memop, idx); 
... 
}
```

下面是ppc指令和IR中间码对照，第一个块为ppc指令

```
0xfff00100:  lis    r1,1

0xfff00104:  ori    r1,r1,0x409c

0xfff00108:  xor    r0,r0,r0

0xfff0010c:  stw    r0,4(r1)

0xfff00110:  mtmsr  r0
```

第二个块为IR中间码

```
0xfff00100:  movi_i32    r1,$0x10000

0xfff00104:  movi_i32    tmp0,$0x409c
             or_i32      r1,r1,tmp0

0xfff00108:  movi_i32    r0,$0x0

0xfff0010c:  movi_i32    tmp1,$0x4
             add_i32     tmp0,r1,tmp1
             qemu_st_i32 r0,tmp0,beul,3

0xfff00110:  movi_i32    nip,$0xfff00114
             mov_i32     tmp0,r0
             call        store_msr,$0,tmp0     
             movi_i32    nip,$0xfff00114
             exit_tb     $0x0
             set_label   $L0
             exit_tb     $0x7f5a0caf8043
```

## 2.3 tcg_gen_code()

在 TCG 的上下文中，术语发生了变化。从 TCG 的角度来看，target不再是 VM，而是host。 TCG要将中间码翻译成在host架构上运行的汇编代码。所以它的target自然是host架构。它被称为*tcg-target*。

因此，*tcg-target*特定代码位于 `tcg/ARCH/tcg-target.inc.c`. 对于我们的 Intel x86 主机，它将是 `tcg/i386/tcg-target.inc.c`，所述*TCG-taget*代码产生由于 [`tcg_gen_code`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/tcg.c#L4013)，上面我们发出了中间码，形如INDEX_op_mov_i32，这个就接收这个中间码，将其转换成host指令。

```c
int tcg_gen_code(TCGContext *s, TranslationBlock *tb)
{
        switch (opc) {
        case INDEX_op_mov_i32:
        case INDEX_op_mov_i64:
            tcg_reg_alloc_mov(s, op);
...
        case INDEX_op_call:
            tcg_reg_alloc_call(s, op);
            break;
        default:
            tcg_reg_alloc_op(s, op);
            break;
        }
    }

...
}
```

第二个过程将 IR转换为x86以供执行，以`INDEX_op_qemu_st_i32`为例，

当执行循环达到 `tcg_gen_code` 和更具体地` tcg_reg_alloc_op`函数，根据操作码`INDEX_op_qemu_st_i32`执行tcg_out_op函数。

```c
static  void  tcg_reg_alloc_op (TCGContext *s, const TCGOp *op) 
{ 
... tcg_out_op (s , op- > opc , new_args, const_args); 
... 
}     
```

*tcg-target*是一个 Intel x86 机器，所以我们会找到合适的`tcg_out_op`定义在文件 `tcg/i386/tcg-target.inc.c`

```c
static  inline  void  tcg_out_op (TCGContext *s, TCGOpcode opc,
                               const TCGArg *args, const  int *const_args) 
{ 
... case INDEX_op_qemu_st_i32:
         tcg_out_qemu_st (s, args, 0 ); 
... 
	case INDEX_op_or_i64:
    case INDEX_op_or_i32:
        a0 = args[0], a1 = args[1], a2 = args[2];
        if (const_args[2]) {
            tcg_out_ori32(s, a0, a1, a2);
        } else {
            tcg_out32(s, OR | SAB(a1, a0, a2));
        }
        break;
    case INDEX_op_xor_i64:
    case INDEX_op_xor_i32:
        a0 = args[0], a1 = args[1], a2 = args[2];
        if (const_args[2]) {
            tcg_out_xori32(s, a0, a1, a2);
        } else {
            tcg_out32(s, XOR | SAB(a1, a0, a2));
        }
        break;
}    
```

从 tcg_out_op()函数中随便截取一段生成二进制指令的代码，tcg_out_modrm_offset( ,OPC_MOVB_EvIz, )，OPC_MOVB_EvIz为x86指令的opcode，为tcg_out_modrm_offset()函数的第二个输入，通过以下对照可以看出最终转换成了二进制。

![[tcg_out_modrm_offset.png]]

```c
static inline void tcg_out_modrm_offset(TCGContext *s, int opc, int r,
                                        int rm, intptr_t offset)
{
    tcg_out_modrm_sib_offset(s, opc, r, rm, -1, 0, offset);
}
```

![[opc_movb_evgv.png]]

![[intel_mov_opcode.png]]

最后将二进制存到了buffer中，在tcg_qemu_tb_exec()函数中读取执行。

## 2.4 地址翻译

TCG翻译的第二阶段（从中间码翻译成x86指令）负责地址的转换，由于 *soft-mmu* 和 virtual TLBs，qemu可以用fast path和slow path两种方式访问guest memory，slow path就是TLB-miss时调用qemu的software MMU来完成地址的转换，如果TLB-hit，那么TLB中及已经保存了需要的地址，qemu可以用host指令（x86）完成内存访问，这里的内存访问为guest physical memory。

翻译成Guest物理地址之后，代码开始执行。执行的过程中，由于没有kvm和硬件的支持，我们怎样利用软件实现来完成Guest地址到Host地址的转化呢？

（guest地址到host地址的转化，摘自张璟同学的报告）

答案则是使用结构体进行管理对应的映射关系。我们都知道，在qemu中使用MemoryRegion对设备（不论是内核设备还是外设）进行地址管理。TB执行过程中，程序拿着翻译好的GVA（guest virtual address）开始找对应的设备，通过MemoryRegion查找到对应的设备。此时设备要开始执行了，设备需要自己的内存时（例如内存条、显卡），问题出现了，设备如何查找对应的内存呢？解决的办法很简单，只需要在MemoryRegion中存储对应的内容，能够顺着一路找到HVA就可以了。找到了HVA，接下来就是Host层面的OS可以处理的了。

在MemoryRegion中，存在这样一个成员：

```c
struct MemoryRegion {
    ...
    RAMBlock *ram_block; //指向对应的RAMBlock
    ...
};
```

这个成员的定义如下：

```c
struct RAMBlock {
   	...
    uint8_t *host;         // 对应的HVA
    ...
};
```

很明显，MemoryRegion可以直接对应查询到HVA。这些信息在设备创建（即向Host使用mmp申请空间）的时候就完成并存储下来了，TB执行的时候可以很方便地查询到，这样就完成了地址的转换。当然了，为了找到准确的地址，还需要进行例如offset和对齐等等操作，这些操作太过细节，这里就不再赘述了。

总结：使用tci时（解释执行），翻译好的指令中地址为guest virtual address，执行时，通过mmu将guest virtual address转化成guest physical address，如果是io地址，执行io_writex或io_readx函数，然后通过MemoryRegion找到host virtual address。

不使用tci，即直接翻译成host指令，翻译好的指令中的地址分为两种情况，如果TLB-hit，guest physical address直接写入TB中，这里的地址已经通过mmu完成了guest virtual address到guest physical address的转换，执行指令时，通过MR找到HVA；如果TLB-miss，将标签写入TB中，此时写入TB中的地址为guest virtual address，标签用于表示地址需要转换。执行时，遇到标签进行GPA到GVA的转换，如果是io地址，通过io_writex或io_readx函数，从MR中找到HVA。

一旦执行循环达到 [`tcg_gen_code`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/tcg.c#L4013) 和更具体地 [`tcg_reg_alloc_op`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/tcg.c#L3575)，QEMU生成`TCG backend-op`为`qemu_st_i32`。

```c
static void tcg_reg_alloc_op(TCGContext *s, const TCGOp *op)
{
...
     tcg_out_op(s, op->opc, new_args, const_args);
...

}
```

在我们的情况下，*tcg-target*是一个 Intel x86 机器，所以我们会找到合适的`tcg_out_op`定义 `tcg/i386/tcg-target.inc.c`

```c
static inline void tcg_out_op(TCGContext *s, TCGOpcode opc,
                              const TCGArg *args, const int *const_args)
{
...
    case INDEX_op_qemu_st_i32:
        tcg_out_qemu_st(s, args, 0);
...
}

```

[`tcg_out_qemu_st`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L2219) 是一个非常有趣的函数。它保存 QEMU 客户内存寻址的内部结构。在这个级别，函数是根据与 TCG 参数（即`TCGArg *args`）相关的一些约定开发的。

```c
static void tcg_out_qemu_st(TCGContext *s, const TCGArg *args, bool is64)
{
    tcg_out_tlb_load(s, addrlo, addrhi, mem_index, opc,
                     label_ptr, offsetof(CPUTLBEntry, addr_write));

    /* TLB Hit.  */
    tcg_out_qemu_st_direct(s, datalo, datahi, TCG_REG_L1, -1, 0, 0, opc);

    /* Record the current context of a store into ldst label */
    add_qemu_ldst_label(s, false, is64, oi, datalo, datahi, addrlo, addrhi,
                        s->code_ptr, label_ptr);
#else
    tcg_out_qemu_st_direct(s, datalo, datahi, addrlo, x86_guest_base_index,
                           x86_guest_base_offset, x86_guest_base_seg, opc);
#endif
}

```

由于*soft-mmu*和虚拟 TLB 的支持，QEMU 在访问客户内存时提供了慢速路径和快速路径。慢速路径可以被视为*TLB-miss*，并意味着对 QEMU 内部实现的 PowerPC soft MMU 的后续调用将地址转换。

如果*TLB-hit*，QEMU 已经在其 vCPU 维护的 TLB 中保存了地址，并且能够使用 Intel x86 指令直接生成最终内存访问。 [`tcg_out_qemu_st_direct`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L2138)。

其背后的机制与以下 3 行相关：

```c
/* try to find a filled TLB entry */
tcg_out_tlb_load(s, addrlo, addrhi, mem_index, opc,
                 label_ptr, offsetof(CPUTLBEntry, addr_write));

/* TLB Hit. So generate a physical guest memory access */
tcg_out_qemu_st_direct(s, datalo, datahi, TCG_REG_L1, -1, 0, 0, opc);

/* TLB Miss. Filled during tlb_load and redirect to soft-MMU */
add_qemu_ldst_label(s, false, is64, oi, datalo, datahi, addrlo, addrhi,
                    s->code_ptr, label_ptr);

```

QEMU vCPU TLBs

首先， [`tcg_out_tlb_load`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L1699) 将生成*host instructions*以检查 TLB 条目。QEMU TLB 是架构通用的，定义在 [cpu-defs.h](https://github.com/qemu/qemu/blob/v4.2.0/include/exec/cpu-defs.h#L109)：

```c
typedef struct CPUTLBEntry {
    /* bit TARGET_LONG_BITS to TARGET_PAGE_BITS : virtual address
       bit TARGET_PAGE_BITS-1..4  : Nonzero for accesses that should not
                                    go directly to ram.
       bit 3                      : indicates that the entry is invalid
       bit 2..0                   : zero
    */
    union {
        struct {
            target_ulong addr_read;
            target_ulong addr_write;
            target_ulong addr_code;
            /* Addend to virtual address to get host address.  IO accesses
               use the corresponding iotlb value.  */
            uintptr_t addend;
        };
        /* padding to get a power of two size */
        uint8_t dummy[1 << CPU_TLB_ENTRY_BITS];
    };
} CPUTLBEntry;

```

由于翻译块生成一次并执行多次（可能），因此生成将动态检查 QEMU 维护的 vCPU TLB 的主机代码很方便。在翻译块的生命周期内，给定的 TLB 条目可能会失效然后再次填充。

该 [`tcg_out_tlb_load`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L1699) 加载代码读起来非常烦人，充满了tcg-target操作码发生器。包含该`tlb_load`算法的生成的 Intel x86_64 转换块 如下所示：

```c
tcg_out_tlb_load:
0x7ffff41888e9 <code_gen_buffer+22716>:	mov    %esp,%edi
0x7ffff41888eb <code_gen_buffer+22718>:	shr    $0x7,%edi
0x7ffff41888ee <code_gen_buffer+22721>:	and    0x338(%rbp),%edi
0x7ffff41888f4 <code_gen_buffer+22727>:	add    0x388(%rbp),%rdi
0x7ffff41888fb <code_gen_buffer+22734>:	lea    0x3(%r12),%esi
0x7ffff4188900 <code_gen_buffer+22739>:	and    $0xfffff000,%esi
0x7ffff4188906 <code_gen_buffer+22745>:	cmp    0x4(%rdi),%esi
0x7ffff4188909 <code_gen_buffer+22748>:	mov    %r12d,%esi
0x7ffff418890c <code_gen_buffer+22751>:	jne    0x7ffff418897f  ---> back to LDST labels
0x7ffff4188912 <code_gen_buffer+22757>:	add    0x10(%rdi),%rsi

```

对于store操作，该`addr_write`字段用于`0x7ffff4188906`在提取中进行比较。该`RDI`寄存器指向`CPUTLBEntry`和`ESI`保存客户端地址。

如果比较失败，则是*TLB -miss*，我们将跳转到稍后将解释的*LDST 标签*。如果比较成功，由于`CPUTLBEntry.addend`，可以将`RSI`寄存器调整为最终的主机地址， 并且可以进行内存访问：

```c
tcg_out_qemu_st_direct:
0x7ffff4188925 <code_gen_buffer+22776>:	movbe  %ebx,(%rsi)
```

TLB 验证实现也可以在 QEMU `cpu_ld/st_xxx`API 函数中找到。如[文档中](https://github.com/qemu/qemu/blob/v4.2.0/docs/devel/loads-stores.rst)所定义 ，它们在guest虚拟地址上运行并**可能导致guest CPU 异常**。因此，他们会检查 TLB 并可能重定向到soft MMU。它们是通过[cpu_ldst_template.h 中的](https://github.com/qemu/qemu/blob/v4.2.0/include/exec/cpu_ldst_template.h)宏 [实现的](https://github.com/qemu/qemu/blob/v4.2.0/include/exec/cpu_ldst_template.h)：

```c
/* generic store macro */

static inline void
glue(glue(glue(cpu_st, SUFFIX), MEMSUFFIX), _ra)(CPUArchState *env,
                                                 target_ulong ptr,
                                                 RES_TYPE v, uintptr_t retaddr)
{
...
    addr = ptr;
    mmu_idx = CPU_MMU_INDEX;
    entry = tlb_entry(env, mmu_idx, addr);
    if (unlikely(tlb_addr_write(entry) !=
                 (addr & (TARGET_PAGE_MASK | (DATA_SIZE - 1))))) {
        oi = make_memop_idx(SHIFT, mmu_idx);
        glue(glue(helper_ret_st, SUFFIX), MMUSUFFIX)(env, addr, v, oi,
                                                     retaddr);
    } else {
        uintptr_t hostaddr = addr + entry->addend;
        glue(glue(st, SUFFIX), _p)((uint8_t *)hostaddr, v);
    }
...
}

```

QEMU LDST 标签

[`LDST labels`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/tcg-ldst.inc.c#L23) 代表*load/store labels*。这是 QEMU 使用的机制，通过 TCG helper程序将*TLB-miss*重定向到对soft MMU 的调用。

该 [`TCGContext`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/tcg.h#L583) 对象保存接收生成的 host assembly（汇编） opcodes的输出缓冲区。每当添加一条指令时，`code_ptr`指向该缓冲区的指针显然都会增加。

在 [`tcg_out_tlb_load`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L1699) 期间，当 QEMU 为*TLB-miss*生成比较和跳转指令时 ，它还会将该位置记录到输出缓冲区中，该缓冲区将保存`JNE`要重定向执行的偏移量。

```c
static inline void tcg_out_tlb_load(TCGContext *s, TCGReg addrlo, TCGReg addrhi,
                                    int mem_index, MemOp opc,
                                    tcg_insn_unit **label_ptr, int which)
{
...
    /* jne slow_path */
    tcg_out_opc(s, OPC_JCC_long + JCC_JNE, 0, 0, 0);
    label_ptr[0] = s->code_ptr;
    s->code_ptr += 4;
...
}

```

此外，当我们回到 [`tcg_out_qemu_st`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L2247)，调用  [`add_qemu_ldst_label`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L1784) 创建一个新的 LDST 标签并记录上下文详细信息，以便稍后准备对 softmmu *slow path* TCG helper的调用：这个稍后调用是在读取二进制x86指令后，如下图所示，helper_le_stl_mmu和store_helper函数都是在code_gen_buffer后面调用的。

```c
static void add_qemu_ldst_label(TCGContext *s, bool is_ld, bool is_64,
                                TCGMemOpIdx oi,
                                TCGReg datalo, TCGReg datahi,
                                TCGReg addrlo, TCGReg addrhi,
                                tcg_insn_unit *raddr,
                                tcg_insn_unit **label_ptr)
{
    TCGLabelQemuLdst *label = new_ldst_label(s);

    label->is_ld = is_ld;
    label->oi = oi;
    label->type = is_64 ? TCG_TYPE_I64 : TCG_TYPE_I32;
    label->datalo_reg = datalo;
    label->datahi_reg = datahi;
    label->addrlo_reg = addrlo;
    label->addrhi_reg = addrhi;
    label->raddr = raddr;
    label->label_ptr[0] = label_ptr[0];
    if (TARGET_LONG_BITS > TCG_TARGET_REG_BITS) {
        label->label_ptr[1] = label_ptr[1];
    }
}

```

![[code_gen_buffer_1.png]]

对 *slow path* helper的调用通过[`tcg_gen_code`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/tcg.c#L4013) 函数，在翻译块结尾生成期间插入， 并调用 [`tcg_out_ldst_finalize`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/tcg-ldst.inc.c#L44). QEMU 检查是否存在*LDST 标签*并生成相应的 TCG helper程序调用。对于我们的store操作， [`tcg_out_ldst_finalize`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/tcg-ldst.inc.c#L44) 将发出 [`tcg_out_qemu_st_slow_path`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L1895)：

```c
int tcg_gen_code(TCGContext *s, TranslationBlock *tb)
{
...
#ifdef TCG_TARGET_NEED_LDST_LABELS
    i = tcg_out_ldst_finalize(s);
    if (i < 0) {
        return i;
    }
#endif
...
}

static int tcg_out_ldst_finalize(TCGContext *s)
{
...
    /* qemu_ld/st slow paths */
    QSIMPLEQ_FOREACH(lb, &s->ldst_labels, next) {
        if (lb->is_ld
            ? !tcg_out_qemu_ld_slow_path(s, lb)
            : !tcg_out_qemu_st_slow_path(s, lb)) {
            return -2;
        }
...
}

static bool tcg_out_qemu_st_slow_path(TCGContext *s, TCGLabelQemuLdst *l)
{
...
    /* "Tail call" to the helper, with the return address back inline.  */
    tcg_out_push(s, retaddr);
    tcg_out_jmp(s, qemu_st_helpers[opc & (MO_BSWAP | MO_SIZE)]);
    return true;
}

```

`slow path helper`调用的准备意味着：

- 解决之前在`JNE`生成过程中记录的标签偏移量
- 参数/寄存器设置
- 调用适当的 [`qemu_st_helper`](https://github.com/qemu/qemu/blob/v4.2.0/tcg/i386/tcg-target.inc.c#L1668)

与其他内存访问函数一样，存储和加载操作存在许多变体：signed, unsigned, byte, word, long, big or little endian。每个都有一个特定的 TCG helper，它是一个 [`store_helper`](https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cputlb.c#L1663)包装器：

```c
/* helper signature: helper_ret_st_mmu(CPUState *env, target_ulong addr,
 *                                     uintxx_t val, int mmu_idx, uintptr_t ra)
 */
static void * const qemu_st_helpers[16] = {
    [MO_UB]   = helper_ret_stb_mmu,
    [MO_LEUW] = helper_le_stw_mmu,
    [MO_LEUL] = helper_le_stl_mmu,
    [MO_LEQ]  = helper_le_stq_mmu,
    [MO_BEUW] = helper_be_stw_mmu,
    [MO_BEUL] = helper_be_stl_mmu,
    [MO_BEQ]  = helper_be_stq_mmu,
};

void helper_be_stl_mmu(CPUArchState *env, target_ulong addr, uint32_t val,
                       TCGMemOpIdx oi, uintptr_t retaddr)
{
    store_helper(env, addr, val, oi, retaddr, MO_BEUL);
}

static inline void QEMU_ALWAYS_INLINE
store_helper(CPUArchState *env, target_ulong addr, uint64_t val,
             TCGMemOpIdx oi, uintptr_t retaddr, MemOp op)
{
...
        if (!tlb_hit_page(tlb_addr2, page2)) {
            if (!victim_tlb_hit(env, mmu_idx, index2, tlb_off, page2)) {
                tlb_fill(env_cpu(env), page2, size2, MMU_DATA_STORE,
                         mmu_idx, retaddr);
                index2 = tlb_index(env, mmu_idx, page2);
                entry2 = tlb_entry(env, mmu_idx, page2);
            }
            tlb_addr2 = tlb_addr_write(entry2);
        }
...
    haddr = (void *)((uintptr_t)addr + entry->addend);
    store_memop(haddr, val, op);
}

```

helper程序检查 TLB，如果有未命中，则调用 [`tlb_fill`](https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cputlb.c#L900)。在任何情况下，一旦地址被解析，它就会使用 [`store_memop`](https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cputlb.c#L1633).

```c
static void tlb_fill(CPUState *cpu, target_ulong addr, int size,
                     MMUAccessType access_type, int mmu_idx, uintptr_t retaddr)
{
    CPUClass *cc = CPU_GET_CLASS(cpu);
    bool ok;

    ok = cc->tlb_fill(cpu, addr, size, access_type, mmu_idx, false, retaddr);
    assert(ok);
}

```

正如您可能猜到的，*填充 TLB*的过程是由soft MMU 完成的，其实现取决于模拟架构。在[PowerPC CPU 初始化](https://github.com/qemu/qemu/blob/v4.2.0/target/ppc/translate_init.inc.c#L10662)期间 ， [`cc->tlb_fill`](https://github.com/qemu/qemu/blob/v4.2.0/accel/tcg/cputlb.c#L900) 设置为 [`ppc_cpu_tlb_fill`](https://github.com/qemu/qemu/blob/v4.2.0/target/ppc/mmu_helper.c#L3041)。

```c
bool ppc_cpu_tlb_fill(CPUState *cs, vaddr addr, int size,
                      MMUAccessType access_type, int mmu_idx,
                      bool probe, uintptr_t retaddr)
{
    PowerPCCPU *cpu = POWERPC_CPU(cs);
    PowerPCCPUClass *pcc = POWERPC_CPU_GET_CLASS(cs);
    CPUPPCState *env = &cpu->env;
    int ret;

    if (pcc->handle_mmu_fault) {
        ret = pcc->handle_mmu_fault(cpu, addr, access_type, mmu_idx);
    } else {
        ret = cpu_ppc_handle_mmu_fault(env, addr, access_type, mmu_idx);
    }
    if (unlikely(ret != 0)) {
        if (probe) {
            return false;
        }
        raise_exception_err_ra(env, cs->exception_index, env->error_code,
                               retaddr);
    }
    return true;
}

```

并且 [`ppc->handle_mmu_fault`](https://github.com/qemu/qemu/blob/v4.2.0/target/ppc/translate_init.inc.c#L5319) 可能最终设置为 [`ppc_hash32_handle_mmu_fault`](https://github.com/qemu/qemu/blob/v4.2.0/target/ppc/mmu-hash32.c#L415)，具体取决于您的 PowerPC CPU 系列。这是 PowerPC 软件 MMU 实现的地方。

## 2.5 helper函数

如果ppc中的指令在x86中也有对应的指令，就是通过上述过程将ppc指令翻译成中间码，中间码翻译成x86指令，如果ppc中的指令没有对应的x86指令，就是通过调用函数实现的，用函数代替指令。这种函数在tcg中叫helper函数，helper函数需要开发者写，比如mtmsr指令，在翻译的第一个过程中通过opcode表找到了gen_mtmsr处理函数，在这个处理函数中会调用gen_helper_store_msr函数。

下面为中间码，可以看到第三行 call store_msr

```c
0xfff00110:  movi_i32    nip,$0xfff00114
             mov_i32     tmp0,r0
             call        store_msr,$0,tmp0  //这里
             movi_i32    nip,$0xfff00114
             exit_tb     $0x0
             set_label   $L0
             exit_tb     $0x7f5a0caf8043
```

中间码翻译成x86指令，如下所示，第三行callq    0x34(%rip)，对应上面的 call store_msr     //这里的地址是x86的地址，是host主机的地址，这个地址看似为12个数，实际为16个数，只是不显示，其实前面有0000，因为目前的处理器硬件限制只有48位地址线。又因为是16进制，所以16**4=64位

```c
0x7f5a0caf8159:  movq     %rbp, %rdi                               
0x7f5a0caf815c:  movl     %ebx, %esi
0x7f5a0caf815e:  callq    *0x34(%rip)  //这里
0x7f5a0caf8164:  movl     $0xfff00114, 0x16c(%rbp)
0x7f5a0caf8182:  movl     %ebx, %edx
0x7f5a0caf8184:  movl     $0xa3, %ecx
0x7f5a0caf8189:  leaq     -0x41(%rip), %r8
0x7f5a0caf8190:  pushq    %r8
0x7f5a0caf8192:  jmpq     *8(%rip)
0x7f5a0caf8198:  .quad  0x000055d62e46eba0
0x7f5a0caf81a0:  .quad  0x000055d62e3895a0
```

mtmsr指令，在第一个过程中通过opcode表找到了gen_mtmsr处理函数，在这个处理函数中会调用gen_helper_store_msr函数，此函数为helper函数。这个时候中间码就不是类似qemu_st_i32了，而是call store_msr。在第二个过程中会将call store_msr翻译成callq 0x34(%rip)，翻译过程完成。当执行这个指令时，会重定向到QEMU中的`helper_store_msr`函数。

# 3 执行

现在回到cpu_exec()函数，此时tb_find()函数已经完成翻译任务，下面就轮到cpu_loop_exec_tb()函数执行已经翻译完成的二进制。

```c
int cpu_exec(CPUState *cpu)
{
    (...)    
        while (!cpu_handle_interrupt(cpu, &last_tb)) {
         	(...)
            tb = tb_find(cpu, last_tb, tb_exit, cflags);
            cpu_loop_exec_tb(cpu, tb, &last_tb, &tb_exit);
          
        }
    }
    return ret;
}
```

```c
static inline void cpu_loop_exec_tb(CPUState *cpu, TranslationBlock *tb,
                                    TranslationBlock **last_tb, int *tb_exit)
{
    ret = cpu_tb_exec(cpu, tb);
}
```

```c
/* Execute a TB, and fix up the CPU state afterwards if necessary */
static inline tcg_target_ulong cpu_tb_exec(CPUState *cpu, TranslationBlock *itb)
{
    ret = tcg_qemu_tb_exec(env, tb_ptr);
    return ret;
}

```

```c
# define tcg_qemu_tb_exec(env, tb_ptr) \
    ((uintptr_t (*)(void *, void *))tcg_ctx->code_gen_prologue)(env, tb_ptr)
```

函数调用已经在上面的代码中依次显示了，最后使用一个宏转向tcg_ctx->code_gen_prologue，最终会转到code_gen_buffer()，读取翻译后的指令。

![[code_gen_buffer_1.png]]

上图显示的bt函数调用栈，从#10开始往上看，依次执行cpu_exec() ---> cpu_loop_exec_tb() ---> code_gen_buffer()，最后来到buffer，读取存储的二进制指令，如果TLB-miss，就会调用helper_le_stl_mmu()函数--->store_helper()函数，store_helper()函数解析地址，如果是io地址，调用io_writex()函数，如上图所示。

```c
        /* Handle I/O access.  */
        if (tlb_addr & TLB_MMIO) {
            io_writex(env, iotlbentry, mmu_idx, val, addr, retaddr,
                      op ^ (need_swap * MO_BSWAP));
            return;
        }
        /* Ignore writes to ROM.  */
        if (unlikely(tlb_addr & TLB_DISCARD_WRITE)) {
            return;
        }
        /* Handle clean RAM pages.  */
        if (tlb_addr & TLB_NOTDIRTY) {
            notdirty_write(env_cpu(env), addr, size, iotlbentry, retaddr);
        }
```



# 4 qemu显示对应汇编指令

显示汇编指令使用-d参数，下图是-d 选项

![[qemu-ppc-d.png]]

比如：qemu-ppc -d in_asm,out_asm,op hello           // hello为打印hello world的程序，具体的看下文

```
in_asm 为guest汇编指令，out_asm为host汇编指令，op为生成的中间码，op_opt为优化后的中间码
```

通过编写汇编指令打印Hello world，来查看两个架构的指令对照

```
# vim hello.s
#############################################(下面的代码为PowerPC汇编指令，#####符号用以分割)
	.data                       # section declaration - variables only
msg:
	.string "Hello, world!\n"
	len = . - msg       # length of our dear string
.text                       # section declaration - begin code
	.global _start
_start:
# write our string to stdout
	li      0,4         # syscall number (sys_write)
	li      3,1         # first argument: file descriptor (stdout)
	                    # second argument: pointer to message to write
	lis     4,msg@ha    # load top 16 bits of &msg
	addi    4,4,msg@l   # load bottom 16 bits
	li      5,len       # third argument: message length
	sc                  # call kernel
# and exit
	li      0,1         # syscall number (sys_exit)
	li      3,1         # first argument: exit code
	sc                  # call kernel
#######################################################（分割）
# powerpc-linux-musl-as -o hello.o hello.s              //powerpc-linux-musl 为powerpc交叉编译链
# powerpc-linux-musl-ld -o hello hello.o
# qemu-ppc -d in_asm,out_asm,op hello
```

说明：这里为什么不使用c语言编写hello world程序？其实用c写也是可以的，但是编译是需要加上-static命令，让程序编成静态链接库，不写-static，默认编成动态链接库，动态链接库会显示找不到文件，而且用汇编编写有一个好处，就是生成的汇编指令是很少的，方便查看。用c语言编写的话，因为有#include引入文件，所以生成的汇编指令很多，不利于查看对照指令。

生成的对照指令如下所示：

![[in_asm.png]]

![[-d_op.png]]

![[out_asm.png]]

# 5 trace

1）编译qemu时要enable trace backend

```
./configure --enable-trace-backends=simple
```

2）添加你想要trace的event
$ vim /tmp/events 

```
translate_block
memory_region_ops_read
memory_region_ops_write
guest_mem_before
exec_tb
```

3）启动虚拟机

```
-trace events=/tmp/events,file=trace.bin
```

其中，在正常启动的的qemu程序中加入"-trace events=/tmp/events,file=trace.bin"，其中/tmp/events就是要跟踪的event，而trace.bin就是trace产生的文件，不能直接读，而要通过工具来读。
4）获取trace结果

```
./qemu-5.2.0/scripts/simpletrace.py /usr/share/qemu/trace-events-all trace-2223 > trace.txt
```

5）有些模块也实现了自己的pretty-print工具，可以更方便的查看结果。比如你trace了9p的模块，可以通过以下工具查看。

analyse-9p-simpletrace.py trace-events trace.bin

# 6 stb指令翻译过程

使用-d选项，打印qemu翻译前的指令，中间码，翻译后的指令，以下过程使用tci解释器

![[stb_before.png]]

中间码：

![[stb_intermediate.png]]

翻译后的指令：

![[stb_after.png]]

在e500内核中的stb指令如下图所示：

![[e500_instruction_table.png]]

![img](file:///C:\Users\wyx\AppData\Roaming\Tencent\Users\981193080\QQ\WinTemp\RichOle\HBYZ}5LKJPKOOVET~$FH$QI.png)

将翻译前的指令使用二进制转换：

![[change_stb.png]]

转换后为100110与手册中的指令一样。

分析指令stb rS，d（rA）

100110 stb

01001  rS   9     RS 寄存器

00001  rA    1   RA  寄存器

0000000000001000   D    8  地址



![[stb_jieshi.png]]

**描述**

**stb**指令将通用寄存器 （GPR） RS 的*24-31*位存储到有效地址 （EA） 处理的存储字块中。

如果 GPR *RA*不是 0，EA 是 GPR *RA*和地址*D*的内容之和，一个 16 位、带符号的二进制补码整数符号扩展到 32 位用于 EA 计算 。如果 GPR *RA*是 0，则 EA 是*D*。

所以这个指令转成中间码时，被分解成了三个中间码，如下所示：

![[stb_intermediate.png]]

下图为生成中间码，movi_i32和add_i32，其中movi_i32是add_i32的前置操作

![[stb_inter_add_mov.png]]

```c
void tcg_gen_addi_i32(TCGv_i32 ret, TCGv_i32 arg1, int32_t arg2)
{
    /* some cases can be optimized here */
    if (arg2 == 0) {
        tcg_gen_mov_i32(ret, arg1);
    } else {
->        TCGv_i32 t0 = tcg_const_i32(arg2);   
->        tcg_gen_add_i32(ret, arg1, t0);
        tcg_temp_free_i32(t0);
    }
}
TCGv_i32 tcg_const_i32(int32_t val)
{
    TCGv_i32 t0;
    t0 = tcg_temp_new_i32();
->  tcg_gen_movi_i32(t0, val);
    return t0;
}
```

下图为生成中间码qemu_st_i32

![[stb_intermediate_code.png]]

```c
void tcg_gen_qemu_st_i32(TCGv_i32 val, TCGv addr, TCGArg idx, MemOp memop)
{
    TCGv_i32 swap = NULL;
    uint16_t info = trace_mem_get_info(memop, idx, 1);

    tcg_gen_req_mo(TCG_MO_LD_ST | TCG_MO_ST_ST);
    memop = tcg_canonicalize_memop(memop, 0, 1);
    trace_guest_mem_before_tcg(tcg_ctx->cpu, cpu_env, addr, info);

    if (!TCG_TARGET_HAS_MEMORY_BSWAP && (memop & MO_BSWAP)) {
        swap = tcg_temp_new_i32();
        switch (memop & MO_SIZE) {
        case MO_16:
            tcg_gen_ext16u_i32(swap, val);
            tcg_gen_bswap16_i32(swap, swap);
            break;
        case MO_32:
            tcg_gen_bswap32_i32(swap, val);
            break;
        default:
            g_assert_not_reached();
        }
        val = swap;
        memop &= ~MO_BSWAP;
    }

    addr = plugin_prep_mem_callbacks(addr);
    gen_ldst_i32(INDEX_op_qemu_st_i32, val, addr, memop, idx);
    plugin_gen_mem_callbacks(addr, info);

    if (swap) {
        tcg_temp_free_i32(swap);
    }
}

static void gen_ldst_i32(TCGOpcode opc, TCGv_i32 val, TCGv addr,
                         MemOp memop, TCGArg idx)
{
    TCGMemOpIdx oi = make_memop_idx(memop, idx);
#if TARGET_LONG_BITS == 32
    tcg_gen_op3i_i32(opc, val, addr, oi);
#else
    if (TCG_TARGET_REG_BITS == 32) {
        tcg_gen_op4i_i32(opc, val, TCGV_LOW(addr), TCGV_HIGH(addr), oi);
    } else {
        tcg_gen_op3(opc, tcgv_i32_arg(val), tcgv_i64_arg(addr), oi);
    }
#endif
}
```

在生成qemu_st_i32后，发出INDEX_op_qemu_st_i32操作码（opcode）

![[tcg_gen_qemu_st_i32_gen_op3.png]]

同时，将操作码和参数保存到全局变量tcg_ctx中。

```c
void tcg_gen_op3(TCGOpcode opc, TCGArg a1, TCGArg a2, TCGArg a3)
{
    TCGOp *op = tcg_emit_op(opc);
    op->args[0] = a1;
    op->args[1] = a2;
    op->args[2] = a3;
}
TCGOp *tcg_emit_op(TCGOpcode opc)
{
    TCGOp *op = tcg_op_alloc(opc);
    QTAILQ_INSERT_TAIL(&tcg_ctx->ops, op, link);
    return op;
}
```

翻译第一个过程结束。

翻译的第二个过程，在tcg_gen_code函数输入为tcg_ctx，下图中的s即为tcg_ctx。将上面保存的数据添加到s->code_ptr中，分配新的寄存器，上文中的寄存器为临时寄存器，第二个过程结束。

![[234523462364.png]]

```c
#if TCG_TARGET_INSN_UNIT_SIZE == 1
static __attribute__((unused)) inline void tcg_out8(TCGContext *s, uint8_t v)
{
    *s->code_ptr++ = v;
}
```

执行

执行过程如下所示

![[io_writex_store_helper.png]]

tcg_qemu_tb_exec函数为/tcg/tci.c文件的1215行，如下所示，执行时先识别qemu_st_i32中间码的操作码INDEX_op_qemu_st_i32，然后执行操作。如果是io地址，就调用io_writex函数。

![[tci.c_1215.png]]

```c
# define qemu_st_b(X) \
    helper_ret_stb_mmu(env, taddr, X, oi, (uintptr_t)tb_ptr)
    
void __attribute__((noinline))
helper_ret_stb_mmu(CPUArchState *env, target_ulong addr, uint8_t val,
                   TCGMemOpIdx oi, uintptr_t retaddr)
{
    store_helper(env, addr, val, oi, retaddr, MO_UB);
}
static inline void QEMU_ALWAYS_INLINE
store_helper(CPUArchState *env, target_ulong addr, uint64_t val,
             TCGMemOpIdx oi, uintptr_t retaddr, MemOp op)
{
    uintptr_t mmu_idx = get_mmuidx(oi);
    uintptr_t index = tlb_index(env, mmu_idx, addr);
    CPUTLBEntry *entry = tlb_entry(env, mmu_idx, addr);
    target_ulong tlb_addr = tlb_addr_write(entry);
    const size_t tlb_off = offsetof(CPUTLBEntry, addr_write);
    unsigned a_bits = get_alignment_bits(get_memop(oi));
    void *haddr;
    size_t size = memop_size(op);

    /* Handle anything that isn't just a straight memory access.  */
    if (unlikely(tlb_addr & ~TARGET_PAGE_MASK)) {
        CPUIOTLBEntry *iotlbentry;
        bool need_swap;
        /* Handle I/O access.  */
        if (tlb_addr & TLB_MMIO) { //TLB_MMIO=128
            io_writex(env, iotlbentry, mmu_idx, val,s
                      op ^ (need_swap * MO_BSWAP));
            return;
        }
    haddr = (void *)((uintptr_t)addr + entry->addend);
    store_memop(haddr, val, op);
}
static void io_writex(CPUArchState *env, CPUIOTLBEntry *iotlbentry,
                      int mmu_idx, uint64_t val, target_ulong addr,
                      uintptr_t retaddr, MemOp op)
{
    CPUState *cpu = env_cpu(env);
    hwaddr mr_offset;
    MemoryRegionSection *section;
    MemoryRegion *mr;
    bool locked = false;
    MemTxResult r;

    section = iotlb_to_section(cpu, iotlbentry->addr, iotlbentry->attrs);
    mr = section->mr;
    mr_offset = (iotlbentry->addr & TARGET_PAGE_MASK) + addr;
    if (!cpu->can_do_io) {
        cpu_io_recompile(cpu, retaddr);
    }
    cpu->mem_io_pc = retaddr;
    if (!qemu_mutex_iothread_locked()) {
        qemu_mutex_lock_iothread();
        locked = true;
    }
    r = memory_region_dispatch_write(mr, mr_offset, val, op, iotlbentry->attrs);
    if (r != MEMTX_OK) {
        hwaddr physaddr = mr_offset +
            section->offset_within_address_space -
            section->offset_within_region;

        cpu_transaction_failed(cpu, physaddr, addr, memop_size(op),
                               MMU_DATA_STORE, mmu_idx, iotlbentry->attrs, r,
                               retaddr);
    }
    if (locked) {
        qemu_mutex_unlock_iothread();
    }
}
```

helper_ret_stb_mmu和store_helper函数通过mmu将GVA转化成GPA，io_writex函数通过MR找到HVA。

![[serial_ioport_write.png]]

GPA 到 HVA的转换的总是从tlb中找索引，再利用索引找mr。指令经过qemu动态翻译后得到GPA地址字面值，qemu需要根据该地址找到对应的MR然后执行相应的读写操作GPA地址字面值在`XXX_helper`(如`load_helper`)中先查tlb，在利用tlb查找MemoryRegionSection(MR section)如果tlb没命中，则先`tlb_fill() -> -> tlb_set_page_with_attrs()`更新tlb。如果命中，则返回`iotlbentry`(TODO：iotlbentry只是一种情况)用于下一阶段section的查找在`tlb_set_page_with_attrs() -> address_space_translate_for_iotlb()`中会执行`phys_page_find()`查找section，计算出section的地址更新tlb，之后查tlb就能查到section了。

```c
static void io_writex(CPUArchState *env, CPUIOTLBEntry *iotlbentry,int mmu_idx, uint64_t val, target_ulong addr,
                      uintptr_t retaddr, MemOp op)
{
    CPUState *cpu = env_cpu(env);
    hwaddr mr_offset;
    MemoryRegionSection *section;
    MemoryRegion *mr;
    bool locked = false;
    MemTxResult r;

    section = iotlb_to_section(cpu, iotlbentry->addr, iotlbentry->attrs);
    mr = section->mr;
   ⭐ mr_offset = (iotlbentry->addr & TARGET_PAGE_MASK) + addr;
    if (!cpu->can_do_io) {
        cpu_io_recompile(cpu, retaddr);
    }
    cpu->mem_io_pc = retaddr;
   //addr经过处理得到偏移量
   ⭐ r = memory_region_dispatch_write(mr, mr_offset, val, op, iotlbentry->attrs); 
    if (r != MEMTX_OK) {
        hwaddr physaddr = mr_offset +
            section->offset_within_address_space -
            section->offset_within_region;

        cpu_transaction_failed(cpu, physaddr, addr, memop_size(op),
                               MMU_DATA_STORE, mmu_idx, iotlbentry->attrs, r,
                               retaddr);
    }
    if (locked) {
        qemu_mutex_unlock_iothread();
    }
}

```

```c
static void serial_mm_write(void *opaque, hwaddr addr,
                            uint64_t value, unsigned size)
{
    SerialMM *s = SERIAL_MM(opaque);
    value &= 255;
    serial_ioport_write(&s->serial, addr >> s->regshift, value, 1);
}
```

```
 SerialMM *s= {
		parent = {
				parent_obj = {
							parent_obj = {
											class = 0x555556cdefd0, 
											free = 0x7ffff7c69f70 <g_free>,
                  						 	Python Exception <class 'gdb.error'> There is no member named keys.: 
											properties = 0x555556f05f00,
                   							ref = 11, 
                  							parent = 0x555556d347e0
                         				}, 
            	id = 0x0, 
          		canonical_path = 0x555556f1b090 "/machine/unattached/device[1]", 
         		realized = true,
        		pending_deleted_event = false, 
           		 opts = 0x0, hotplugged = 0, 
           		 allow_unplug_during_migration = false, 
           		 parent_bus = 0x555556d349d0, 
          		 gpios = {lh_first = 0x555556f1b420}, 
         		clocks = {lh_first = 0x0}, 
         		child_bus = {lh_first = 0x0}, 
        	    num_child_bus = 0, 
        	    instance_id_alias = 17664,
        	    alias_required_for_version = 2, 
        	    reset = {
            			count = 0, 
            			hold_phase_pending = false,
              		    exit_phase_in_progress = false
                    }
                }, 
    			 num_mmio = 1, 
   				  mmio =  {
     					{
     						addr = 18446744073709551615,
          					memory = 0x555556f1a660
        				}, 
       						 {
        					addr = 0, 
        					memory = 0x0
        				 } <repeats 31 times>}, 
       					 num_pio = 0, 
        				pio = {0 <repeats 32 times>}
            			 }, 
     serial =  {
     				parent = {
      							parent_obj = {class = 0x555556d1dd30, 
      											free = 0x0, Python Exception <class 'gdb.error'> There is no member named keys.: 
												properties = 0x555556f05f60, 
												ref = 1, 
												parent = 0x555556f1a1e0
											 }, 
								id = 0x0, 
       							canonical_path = 0x555556f1b060 "/machine/unattached/device[1]/serial", 
       							realized = true, 
       							pending_deleted_event = false, 
       							opts = 0x0, 
       							hotplugged = 0, 
                                allow_unplug_during_migration = false, 
                                parent_bus = 0x0,
                                gpios = {lh_first = 0x0}, 
                                clocks = {lh_first = 0x0}, 
                                child_bus = {lh_first = 0x0}, 
                                num_child_bus = 0, 
                                instance_id_alias = -1, 
                                alias_required_for_version = 0, 
                                reset = {
                                			count = 0, 
                                			hold_phase_pending = false, 
                                			exit_phase_in_progress = false}
                                }, 
                     divider = 12, 
                     rbr = 0 '\000', 
   					 thr = 0 '\000',
                     tsr = 0 '\000',
                     ier = 0 '\000', 
                     iir = 1 '\001', 
                     lcr = 0 '\000', 
                     mcr = 8 '\b', 
                     lsr = 96 '`', 
                     msr = 176 '\260', 
                     scr = 0 '\000', 
                     fcr = 0 '\000', 
    				 fcr_vmstate = 0 '\000', 
    				 thr_ipending = 0, 
    				 irq = 0x555556ef5870,
                     chr = {
                     			chr = 0x555556d41550, 
                    		    chr_event = 0x5555559f18ca <serial_event>, 
     						    chr_can_read = 0x5555559f175b <serial_can_receive1>, 
     						    chr_read = 0x5555559f1781 <serial_receive1>, 
     						    chr_be_change = 0x5555559f1e15 <serial_be_change>,
                                opaque = 0x555556f1a500, 
     							 tag = 0, fe_open = 1
     					   }, 
     				last_break_enable = 0, 
     				baudbase = 399193, 
     				tsr_retry = 0,
                    watch_tag = 0,
                    wakeup = false, 
                    last_xmit_ts = 0, 
                    recv_fifo = {data = 0x555556f1ae30 "", 
     							 capacity = 16, 
     							 head = 0, 
     							 num = 0}, 
     				xmit_fifo = {data = 0x555556f1b000 "\340+\002\367\377\177", 
     								capacity = 16,
                                    head = 0, 
                                    num = 0}, 
                    recv_fifo_itl = 0 '\000', 
    				fifo_timeout_timer = 0x555556f1afc0,
                    timeout_ipending = 0, 
                    char_transmit_time = 1041660, 
                    poll_msl = -1,
                    modem_status_poll = 0x555556f1af80,
                    io = {
                    parent_obj = {
       									 class = 0x555556b76ef0, free = 0x0, Python Exception <class 'gdb.error'> There is no 											 member named keys.: 
										 properties = 0x555556f16c00, 
										 ref = 1,
                                         parent = 0x555556f1a1e0},      
                    romd_mode = true, 
                    ram = false, 
                    subpage = false, 
                    readonly = false, 
                    nonvolatile = false，
                    rom_device = false, 
                    flush_coalesced_mmio = false, 
                    dirty_log_mask = 0 '\000', 
                    is_iommu = false, 
                    ram_block = 0x0, 
                    owner = 0x555556f1a1e0, 
                    ops = 0x5555567c4890 <serial_mm_ops+80>,
                    opaque = 0x555556f1a1e0, 
                    container = 0x555556e68ce0,
                    size = 8, 
                    addr = 17664, 
                    destructor = 0x555555c301f1 <memory_region_destructor_none>, 
     				align = 0, 
     				terminates = true,
                    ram_device = false, 
                    enabled = true, 
                    warning_printed = false, 
                    vga_logging_count = 0 '\000',
                    alias = 0x0, 
                    alias_offset = 0,
                    priority = 0, 
     				 subregions = {tqh_first = 0x0, 
     				 				tqh_circ = {tql_next = 0x0, 
     				 							tql_prev = 0x555556f1a708}
     				 			   },
                    subregions_link = {tqe_next = 0x555556e7b930, 
                    					tqe_circ = {tql_next = 0x555556e7b930, 
         											 tql_prev = 0x555556f5a168}
         							   }, 
      				coalesced = {tqh_first = 0x0, 
      							tqh_circ = {tql_next = 0x0, tql_prev = 0x555556f1a728}
      							},
                    name = 0x555556f1b300 "serial",
                    ioeventfd_nb = 0, 
    				  ioeventfds = 0x0}
    		       },
    regshift = 0 '\000',
    endianness = 1 '\001'
}
```

# 7 参考文献

https://github.com/airbus-seclab/qemu_blog   此文档为主要的参考文档

[USENIX '05 — Technical Paper, FREENIX Track](https://www.usenix.org/legacy/event/usenix05/tech/freenix/full_papers/bellard/bellard_html/)    qemuTCG论文

https://wiki.qemu.org/Documentation/TCG 官方文档

https://wiki.qemu.org/Documentation/TCG/frontend-ops   官方文档，TCG的中间码解释

https://wiki.qemu.org/Documentation/TCG/backend-ops   官方文档

https://gitlab.com/qemu-project/qemu/-/blob/master/tcg/README 官方文档，TCG readme

https://stackoverflow.com/questions/20675226/qemu-code-flow-instruction-cache-and-tcg#   流程图，以及函数调用栈 

https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html x86指令官方手册

https://stackoverflow.com/questions/13005303/how-does-native-android-code-written-for-arm-run-on-x86/44505097#44505097 qemu的指令转换显示命令

http://blog.vmsplice.net/2016/01/qemu-internals-how-guest-physical-ram.html 地址转换

https://www.skywind.me/blog/archives/340     https://blog.csdn.net/gumpforgood/article/details/1788179powerpc    https://developer.ibm.com/articles/l-ppc/?mhsrc=ibmsearch_a&mhq=ppc
汇编helloworld 用于显示对照指令，这三个网页是一个，最后那个是官方文档  ,,ԾㅂԾ,,

https://www.bilibili.com/video/BV12Z4y1c74c?p=6  b站关于qemu的视频，很有用，但也没那么有用